{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4da90262",
   "metadata": {},
   "source": [
    "## 최적화 알고리즘"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f591b23",
   "metadata": {},
   "source": [
    "### 1. 아다그라드(Adagrad, Adaptive gradient)\n",
    "\n",
    "- 아다그라드는 변수(가중치)의 업데이트 횟수에 따라 학습률을 조정하는 방법이다\n",
    "\n",
    "- 아다그라드는 많이 변화하지 않는 변수들의 학습률은 크게 하고, 많이 여러 번 변화하는 변수들의 학습률은 작게 한다.\n",
    "\n",
    "- 즉, 많이 변화한 변수는 최적 값에 근접했을 것이라는 가정하에 작은 크기로 이동하면서 세밀하게 값을 조정하고, 반대로 적게 변화한 변수들은 학습률을 크게 하여 빠르게 오차 값을 줄이고자 하는 방법이다.\n",
    "\n",
    "$$w(i + 1) = w(i) - \\frac{\\eta}{\\sqrt{G(i) + \\epsilon}} \\nabla E(w(i))$$\n",
    "$$G(i) = G(i - 1) + (\\nabla E(w(i)))^2$$\n",
    "\n",
    "$$\n",
    "\\begin{aligned}\n",
    "G(i) &: \\text{기울기 제곱의 누적합} \\\\\n",
    "\\nabla E(w(i)) &: \\text{현재의 기울기} \\\\\n",
    "\\eta &: \\text{학습률} \\\\\n",
    "\\epsilon &: \\text{0으로 나누는 것을 방지하는 아주 작은 값값}\n",
    "\\end{aligned}\n",
    "$$ \n",
    "\n",
    "- 파라미터마다 다른 학습률을 주기 위해 G 함수를 추가\n",
    "\n",
    "- 이때 G 값은 이전 G 값의 누적(기울기 크기의 누적)\n",
    "\n",
    "- 기울기가 크면 G 값이 커지기 때문에 $\\frac{\\eta}{\\sqrt{G(i) + \\epsilon}}$ 값은 작아진다.\n",
    "\n",
    "- 즉, 파라미터가 많이 학습되었으면 작은 학습률로 업데이트되고, 파라미터 학습이 덜 되었으면 개선의 여지가 많기 때문에 높은 학습률로 업데이트 된다.\n",
    "\n",
    "- 아다그라드는 기울기가 0에 수렴하는 문제가 있어 사용하지 않으며, 대신에 알엠에스프롭을 사용한다.\n",
    "\n",
    "- 파이토치에서 아다그라드 구현 방법"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0af8a13",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.Adagrad(model.parameters(), lr=0.01) # 학습률 기본값은 1e - 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4552721c",
   "metadata": {},
   "source": [
    "### 2. 아다델타 (Adadelta, Adaptive delta)\n",
    "\n",
    "- 아다델타는 아다그라드에서 G 값이 커짐에 따라 아직 최소값에 도달하지 못한 경우에도 학습이 멈추는 문제를 해결하기 위해 등장한 방법이다.\n",
    "\n",
    "- 아다델타는 아다그라드의 수식에서 학습률($\\eta$)을 D 함수(가중치의 변화량($\\nabla$) 크기를 누적한 값)로 변환했기 때문에 학습률에 대한 하이퍼파라미터가 별도로 필요하지 않는다.\n",
    "\n",
    "$$ w(i + 1) = w(i) - \\frac{\\sqrt{D(i-1) + \\epsilon}}{\\sqrt{G(i) + \\epsilon}} \\nabla E(w(i)) $$\n",
    "$$ G(i) = \\gamma G(i-1) + (1-\\gamma)(\\nabla E(w(i)))^2 $$\n",
    "$$ D(i) = \\gamma D(i-1) + (1-\\gamma)(\\nabla(w(i)))^2 $$\n",
    "\n",
    "- 파이토치에서 아다델타 구현 방법"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6471698",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.Adadelta(model.parameters(), lr=1.0) # 학습률 기본값은 1.0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a73cddf",
   "metadata": {},
   "source": [
    "### 3. 알엠에스프롭(RMSProp)\n",
    "\n",
    "- 알엠에스프롭은 아다그라드의 $G(i)$ 값이 무한히 커지는 것을 방지하고자 제안된 방법이다.\n",
    "\n",
    "$$ w(i + 1) = w(i) - \\frac{\\eta}{\\sqrt{G(i) + \\epsilon}} \\nabla E(w(i)) $$\n",
    "$$ G(i) = \\gamma G(i - 1) + (1 - \\gamma)(\\nabla E(w(i)))^2 $$\n",
    "\n",
    "- 아다그라드에서 학습이 안 되는 문제를 해결하기 위해 G 함수에서 $\\gamma$만 추가한다.\n",
    "\n",
    "- 즉, G 값이 너무 크면 학습률이 작아져 학습이 안 될 수 있으므로 사용자가 $\\gamma$값을 이용하여 학습률 크기를 비율로 조정할 수 있도록 한다.\n",
    "\n",
    "- 파이토치에서 알엠에스프롭 구현 방법"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f975b2d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.RMSprop(model.parameters(), lr=0.01) # 학습률 기본값은 1e - 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "485c7cf2",
   "metadata": {},
   "source": [
    "### 4. 모멘텀(Momentum)\n",
    "\n",
    "- 경사 하강법과 마찬가지로 매번 기울기를 구하지만, 가중치를 수정하기 전에 이전 수정 방향(+, -)을 참고하여 같은 방향으로 일정한 비율만 수정하는 방법이다.\n",
    "\n",
    "- 수정이 양(+)의 방향과 음(-)의 방향으로 순차적으로 일어나는 지그재그 현상이 줄어들고, 이전 이동 값을 고려하여 일정 비율만큼 다음 값을 결정하므로 관성 효과를 얻을 수 있는 장점이 있다.\n",
    "\n",
    "- SGD(확률적 경사 하강법)와 함께 사용한다.\n",
    "\n",
    "- SGD 모멘텀(SGD with Momentum)은 확률적 경사 하강법에서 기울기$(\\eta \\nabla E(w(i)))$를 속도$(v, velocity)$로 대체하여 사용하는 방식으로, 이전 속도의 일정 부분을 반영한다.\n",
    "\n",
    "- 즉, 이전에 학습했던 속도와 현재 기울기를 반영해서 가중치를 구한다.\n",
    "\n",
    "$$ w(i + 1) = w(i) - v(i) $$\n",
    "$$ v(i) = \\gamma v(i - 1) + \\eta \\nabla E(w(i)) $$\n",
    "\n",
    "- 파이토치에서 모멘텀 구현 방법"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41ac98bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.SGD(model.parameters(), lr=0.01, momentum=0.9)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71070105",
   "metadata": {},
   "source": [
    "- momentum 값은 0.9에서 시작하며 0.95, 0.99처럼 조금씩 증가시키면서 사용한다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10edd400",
   "metadata": {},
   "source": [
    "### 5. 네스테로프 모멘텀 (Nesterov Accelerated Gradient, NAG)\n",
    "\n",
    "- 네스테로프 모멘텀은 모멘텀 값과 기울기 값이 더해져 실제 값을 만드는 기존 모멘텀과 달리 모멘텀 값이 적용된 지점에서 기울기 값을 계산한다.\n",
    "\n",
    "- 모멘텀 방법은 멈추어야 할 시점에서도 관성에 의해 훨씬 멀리 갈 수 있는 단점이 있다. (오버 슈팅 문제)\n",
    "\n",
    "- 네스테로프 방법은 모멘텀으로 절반 정도 이동한 후 어떤 방식으로 이동해야 하는지 다시 계산하여 결정하기 때문에 모멘텀 방법의 단점을 극복할 수 있다.\n",
    "\n",
    "- 모멘텀 방법의 이점인 빠른 이동 속도는 그대로 가져가면서 멈추어야 할 적절한 시점에서 제동을 거는 데 훨씬 용이하다.\n",
    "\n",
    "- 수식은 다음과 같다.\n",
    "\n",
    "$$ w(i + 1) = w(i) - v(i) $$\n",
    "$$ v(i) = \\gamma v(i - 1) + \\eta \\nabla E(w(i) - \\gamma v(i - 1)) $$\n",
    "\n",
    "- 모멘텀과 비슷하지만 속도(v)를 구하는 과정에서 조금 차이가 있다.\n",
    "\n",
    "- 이전에 학습했던 속도에 현재 가중치에서 이전 속도를 일정 비율 뺀 변화량을 반영해서(더해서) 가중치를 구한다.\n",
    "\n",
    "![image1](../images/optimization_algorithms/image1.png)\n",
    "\n",
    "- 파이토치에서 네스테로프 모멘텀 구현 방법"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0baf1c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.SGD(model.parameters(), lr=0.01, momentum=0.9, nesterov=True) # nesterov 기본값은 False"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd2bcde2",
   "metadata": {},
   "source": [
    "### 4. 아담(Adam, Adaptive Moment Estimation)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3aab3207",
   "metadata": {},
   "source": [
    "- 아담은 알엠에스프롭과 모멘텀의 장점을 결합한 경사 하강법이다.\n",
    "\n",
    "- 알엠에스프롭 특징인 기울기의 제곱을 지수 평균한 값과 모멘텀 특징인 $v(i)$를 수식에 활용한다.\n",
    "\n",
    "- 즉, 알엠에스프롭의 $G$ 함수와 모멘텀의 $v(i)$를 사용하여 가중치를 업데이트한다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f7909fa",
   "metadata": {},
   "source": [
    "$$ w(i + 1) = w(i) - \\frac{\\eta}{\\sqrt{G(i) + \\epsilon}} v(i) $$\n",
    "$$ G(i) = \\gamma_2 G(i - 1) + (1 - \\gamma_2)(\\nabla (E(w(i))))^2 $$\n",
    "$$ v(i) = \\gamma_1 v(i - 1) + \\eta \\nabla E(w(i)) $$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26a7c6c4",
   "metadata": {},
   "source": [
    "- 파이토치에서 아담 구현 방법"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac693bfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.AdamD(model.parameters(), lr=0.01) # 학습률 기본값은 1e - 3"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
