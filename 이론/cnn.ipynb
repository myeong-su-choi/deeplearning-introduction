{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ffbd844b",
   "metadata": {},
   "source": [
    "## Convolution Neural Network"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe419fe7",
   "metadata": {},
   "source": [
    "### 이미지 컨벌루션 연산 과정\n",
    "\n",
    "- 이미지 위에서 stride 값 만큼 filter(kernel)을 이동시키면서 겹쳐지는 부분의 각 원소의 값을 곱해서 모두 더한 값을 출력으로 하는 연산\n",
    "\n",
    "![Image](https://github.com/user-attachments/assets/290e87e8-2990-4e2f-a6a2-7671d19daacb)\n",
    "![Image](https://github.com/user-attachments/assets/2176a9f3-1574-4654-b24f-1d05f7b5a606)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40b4782d",
   "metadata": {},
   "source": [
    "### 컨벌루션 필터의 슬라이딩 순서\n",
    "\n",
    "- 보통 가로 방향으로 한 줄을 슬라이딩하고 나서 세로 반향으로 한 칸씩 아래로 이동하는 순서로 진행\n",
    "\n",
    "![Image](https://github.com/user-attachments/assets/98e0b0d0-747b-48bf-9bef-aacd0184a4f9)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2152c53e",
   "metadata": {},
   "source": [
    "### 풀링 연산을 이용한 서브샘플링\n",
    "\n",
    "- 풀링 연산은 이미지상에서 풀링 필터를 슬라이딩하면서 요약 통계량을 구하는 연산\n",
    "\n",
    "- 다음 그림과 같이 4x4 이미지에 2x2 풀링 필터로 맥스 풀링과 평균 풀링을 구행한다고 가정\n",
    "\n",
    "- 파란색, 주황색, 녹색, 노란색 영역이 풀링 필터와 이미지가 겹쳐지는 영역이며, 각 영역에서 최댓값과 평균을 구하면 오른쪽의 2x2 이미지가 생성된다.\n",
    "\n",
    "![Image](https://github.com/user-attachments/assets/24418d41-0aa0-4200-ac77-0b8fe5e9db0b)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f0fcfc4",
   "metadata": {},
   "source": [
    "### 스트라이드\n",
    "\n",
    "- 컨벌루션 연산과 풀링 연산을 할 때 필터의 슬라이딩 간격을 스트라이드라고 한다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "371cd09f",
   "metadata": {},
   "source": [
    "#### 스트라이드 크기별 컨벌루션 연산\n",
    "\n",
    "- 다음과 같이 7x7 이미지와 3x3 콘벌루션 필터가 있다고 가정\n",
    "\n",
    "- 스트라이드 1로 콘벌루션 연산을 한다면 출력 이미지의 크기는 어떻게 될까?\n",
    "\n",
    "![Image](https://github.com/user-attachments/assets/6b72375b-0f54-4ded-8e2b-b2715b761399)\n",
    "\n",
    "- 스트라이드 2와 3으로 컨벌루션 연산을 한다면 출력 이미지의 크기는 어떻게 될까?\n",
    "\n",
    "![Image](https://github.com/user-attachments/assets/32b5489d-0219-4804-91d3-a39719e8a4c9)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9191ff5f",
   "metadata": {},
   "source": [
    "#### 컨벌루션 연산의 출력 크기\n",
    "- 컨벌루션 연산의 출력 크기는 수식으로 간단히 계산할 수 있다.\n",
    "$$ O = \\frac{N - F}{S} + 1 $$\n",
    "$$ N: 입력 데이터의 크기 $$\n",
    "$$ F: 컨벌루션 필터 크기 $$\n",
    "$$ S: 스트라이드 $$\n",
    "$$ O: 출력 데이터 크기 $$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f60c09f",
   "metadata": {},
   "source": [
    "#### 컨벌루션 연산의 출력 크기 계산 예시\n",
    "- 이미지가 7 x 7, 컨벌루션 필터가 3 x 3, 스트라이드가 1일 때 출력의 크기를 계산\n",
    "$$ O = \\frac{N - F}{S} + 1 = \\frac{7 - 3}{1} + 1 = 5 $$\n",
    "\n",
    "- 스트라이드가 2인 경우에도 출력의 크기는 3 x 3이 되는 것을 확인할 수 있다.\n",
    "$$ O = \\frac{N - F}{S} + 1 = \\frac{7 - 3}{2} + 1 = 3 $$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d84142b",
   "metadata": {},
   "source": [
    "### 패딩\n",
    "\n",
    "- 콘벌루션 연산을 하면 콘벌루션 필터가 입력 이미지 안에서만 슬라이딩하므로 출력 이미지의 크기는 입력 이미지의 크기보다 작아질 수밖에 없다.\n",
    "\n",
    "- 콘벌루션 연산 뒤에도 이미지 크기를 유지하려면 이미지에 픽셀을 추가하여 크기를 늘려줘야 하는데, 이와 같은 방법을 이미지 패딩이라고 한다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87f9fd1b",
   "metadata": {},
   "source": [
    "#### 패딩을 고려한 콘벌루션 연산의 출력 크기\n",
    "\n",
    "$$ O = \\frac{(N + 2 \\times P) - F}{S} + 1 $$\n",
    "$$ N: 입력 데이터의 크기 $$\n",
    "$$ F: 패딩 $$\n",
    "$$ F: 컨벌루션 필터 크기 $$\n",
    "$$ S: 스트라이드 $$\n",
    "$$ O: 출력 데이터 크기 $$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d0f0b56",
   "metadata": {},
   "source": [
    "#### 7 x 7 이미지 패딩 예시\n",
    "\n",
    "- 7 x 7 이미지에 패딩을 추가하여 9 x 9 이미지를 생성\n",
    "\n",
    "![Image](https://github.com/user-attachments/assets/7d1e52af-cc5d-4894-a601-88783a4ff77c)\n",
    "\n",
    "- 앞의 식에 N = 7, P = 1, F = 3, S = 1을 대입하면 컨벌루션 연산 후에도 이미지 크기가 7로 유지되는 것을 알 수 있다.\n",
    "$$ O = \\frac{(N + 2 \\times P) - F}{S} + 1 = \\frac{(7 + 2 \\times 1) - 3}{1} + 1 = 7 $$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ada66428",
   "metadata": {},
   "source": [
    "#### 이미지 크기를 유지하기 위한 패딩 크기 계산\n",
    "- 컨벌루션 연산 후 이미지 크기를 유지하기 위한 패딩 크기는 어떻게 계산해야 할까?\n",
    "\n",
    "- 먼저 앞의 출력 계산식을 P에 대해 정리\n",
    "\n",
    "- 다음과 같이 출력 이미지를 원하는 크기로 만들기 위한 입력 이미지의 패딩 크기를 계산하는 식이 된다.\n",
    "\n",
    "$$ P = \\frac{(O - 1) \\times S - (N - F)}{2} $$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26dc99b2",
   "metadata": {},
   "source": [
    "## 1D convolution and padding (with numpy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "27a63a92",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Conv1d Implementation:  [ 8 11  7  9  4]\n",
      "Numpy Results:  [ 7  8  9 11  3]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "def conv1d(x, w, p=0, s=1):\n",
    "    w_rot = np.array(w)\n",
    "    x_padded = np.array(x)\n",
    "    if p > 0:\n",
    "        zero_pad = np.zeros(shape=p)\n",
    "        x_padded = np.concatenate([zero_pad, x_padded, zero_pad])\n",
    "    res = []\n",
    "    for i in range(0, int((len(x) + 2 * p - len(w)) / s) + 1):\n",
    "        j = s * i\n",
    "        res.append(np.sum(x_padded[j:j+w_rot.shape[0]] * w_rot))\n",
    "    return np.array(res)\n",
    "\n",
    "x = [1, 0, 2, 3, 0, 1, 1]\n",
    "w = [2, 1, 3]\n",
    "print('Conv1d Implementation: ', conv1d(x, w, p=0, s=1))\n",
    "print('Numpy Results: ', np.convolve(x, w, mode='valid')) # w = [3, 1, 2], p=0, s=1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4933ca75",
   "metadata": {},
   "source": [
    "## 1D convolution and padding (with PyTorch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e68dee2f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1., 0., 2., 3., 0., 1., 1.]) \n",
      " tensor([2., 1., 3.]) \n",
      "\n",
      "tensor([[[1., 0., 2., 3., 0., 1., 1.]]]) \n",
      " tensor([[[2., 1., 3.]]]) \n",
      "\n",
      "tensor([ 8., 11.,  7.,  9.,  4.])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "\n",
    "i = torch.tensor([1, 0, 2, 3, 0, 1, 1], dtype=torch.float32, requires_grad=False)\n",
    "k = torch.tensor([2, 1, 3], dtype=torch.float32, requires_grad=False)\n",
    "\n",
    "print(i, '\\n', k, '\\n')\n",
    "\n",
    "data = i.view(1, 1, i.shape[0])\n",
    "kernel = k.view(1, 1, k.shape[0])\n",
    "\n",
    "print(data, '\\n', kernel, '\\n')\n",
    "\n",
    "res = F.conv1d(data, kernel, stride=1, padding=0).squeeze()\n",
    "\n",
    "print(res)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddcc72a3",
   "metadata": {},
   "source": [
    "## 2D convolution + padding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3a94257c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Conv2d Implementation: \n",
      " [[10. 24. 33. 14.]\n",
      " [19. 24. 24. 14.]\n",
      " [13. 28. 25. 17.]\n",
      " [11. 17. 14.  9.]]\n",
      "Scipy Result: \n",
      " [[10 24 33 14]\n",
      " [19 24 24 14]\n",
      " [13 28 25 17]\n",
      " [11 17 14  9]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import scipy.signal\n",
    "\n",
    "def conv2d(X, W, p=(1, 1), s=(1, 1)):\n",
    "    W_rot = np.array(W)[::-1, ::-1]\n",
    "    X_orig = np.array(X)\n",
    "    n1 = X_orig.shape[0] + 2 * p[0]\n",
    "    n2 = X_orig.shape[1] + 2 * p[1]\n",
    "    X_padded = np.zeros(shape=(n1, n2))\n",
    "    X_padded[p[0]:p[0] + X_orig.shape[0], p[1]:p[1] + X_orig.shape[1]] = X_orig\n",
    "\n",
    "    res = []\n",
    "    for i in range(0, int((X_padded.shape[0] - W_rot.shape[0]) / s[0]) + 1):\n",
    "        res.append([])\n",
    "        for j in range(0, int((X_padded.shape[1] - W_rot.shape[1]) / s[1]) + 1):\n",
    "            X_sub = X_padded[i*s[0]:i*s[0]+W_rot.shape[0], j*s[1]:j*s[1]+W_rot.shape[1]]\n",
    "            res[-1].append(np.sum(X_sub * W_rot))\n",
    "    return (np.array(res))\n",
    "\n",
    "X = [[1, 2, 3, 4], [5, 6, 1, 3], [1, 2, 0, 2], [3, 4, 3, 2]]\n",
    "W = [[1, 0, 3], [1, 2, 1], [0, 1, 1]]\n",
    "print('Conv2d Implementation: \\n', conv2d(X, W, p=(1, 1), s=(1, 1)))\n",
    "print('Scipy Result: \\n', scipy.signal.convolve2d(X, W, mode='same'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
